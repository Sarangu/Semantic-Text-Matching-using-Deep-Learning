{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9e271b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e5b248c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import time\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f70314b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3644bd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This file contains code that involves generating the candidates for an input query\n",
    "\n",
    "#Importing necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import faiss\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "\n",
    "#Using pre-trained models for tokenization and embeddings generation\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "model.eval()\n",
    "\n",
    "def get_sentence_embeddings(data):\n",
    "    tokens = {'input_ids': [], 'attention_mask': []}\n",
    "\n",
    "    for sentence in data:\n",
    "        # tokenize sentence and append to dictionary lists\n",
    "        new_tokens = tokenizer.encode_plus(sentence, max_length=128, truncation=True,\n",
    "                                          padding='max_length', return_tensors='pt')\n",
    "        tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "        tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
    "#     print(\"tokens made!\")\n",
    "    \n",
    "    # Flatten list of tensors into single tensor and convert to cuda tensors if necessary\n",
    "    tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "    tokens['attention_mask'] = torch.stack(tokens['attention_mask'])\n",
    "    \n",
    "    #Pass tokens to model to obtain output\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "    \n",
    "    #Obtain embeddings as last hidden state\n",
    "    embeddings = outputs.last_hidden_state\n",
    "\n",
    "    #Create mask\n",
    "    attention_mask = tokens['attention_mask']\n",
    "    mask = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "\n",
    "    #Compute masked embeddings\n",
    "    masked_embeddings = embeddings * mask\n",
    "    summed = torch.sum(masked_embeddings, 1)\n",
    "    summed_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
    "    \n",
    "    #Perform mean pooling\n",
    "    mean_pooled = (summed / summed_mask)\n",
    "    \n",
    "    #Convert torch tensor to numpy array\n",
    "    embeddings_arr = mean_pooled.detach().numpy()\n",
    "\n",
    "    return embeddings_arr\n",
    "\n",
    "def obtain_trained_embeddings():\n",
    "    #Reading embeddings from pkl file into a list\n",
    "    objects = []\n",
    "    with (open(\"./embeddings/embeddings_stack_overflow_answer_titles.txt\", \"rb\")) as openfile:\n",
    "        while True:\n",
    "            try:\n",
    "                objects.append(pickle.load(openfile))\n",
    "            except EOFError:\n",
    "                break\n",
    "    embeddings = [item for sublist in objects for item in sublist]\n",
    "    return embeddings\n",
    "\n",
    "def faiss_index(embeddings):\n",
    "    #Length of each SBERT embedding is 768\n",
    "    d= 768\n",
    "    \n",
    "    #Creating faiss indices, adding for all embeddings\n",
    "    index = faiss.IndexFlatL2(d)\n",
    "    index.add(np.stack(embeddings, axis=0))\n",
    "    \n",
    "    return index\n",
    "\n",
    "def run_query(query, pre_loaded_embeddings=None, return_rate=10):\n",
    "    query_embedding = get_sentence_embeddings(query)\n",
    "    \n",
    "    #Obtain pre-processed data\n",
    "    res = pd.read_pickle('../formatted_data/stackoverflow/unique_answer_titles.pkl')\n",
    "    res = [x for x in res if str(x) != 'nan']\n",
    "    \n",
    "    #Calling functions to obtain embeddings of corpus and create faiss index\n",
    "    if pre_loaded_embeddings is not None:\n",
    "        embeddings = pre_loaded_embeddings\n",
    "    else:\n",
    "        embeddings = obtain_trained_embeddings()\n",
    "    index = faiss_index(embeddings)\n",
    "    \n",
    "    for query, query_embedding in zip(query, query_embedding):\n",
    "        distances, indices = index.search(np.asarray(query_embedding).reshape(1,768), return_rate)\n",
    "        yield [res[indices[0,idx]] for idx in range(return_rate)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89fc4f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_links = pickle.load(open(\"../formatted_data/stackoverflow/q_link_pairs_titles_only.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cfbdbeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294444\n"
     ]
    }
   ],
   "source": [
    "all_embeddings = obtain_trained_embeddings()\n",
    "print(len(all_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa2f298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [x for x in pd.read_pickle('../formatted_data/stackoverflow/unique_answer_titles.pkl') if str(x) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0488f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20)\n",
    "short_q_links = random.choices(q_links[:len(all_embeddings)], k=1000)\n",
    "all_q_list = set([q for (q,a) in q_links])\n",
    "short_a_list = [a for (q,a) in short_q_links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e4eb3006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_rate(sample, embeddings, return_size):\n",
    "    hits = 0\n",
    "    result_sets = run_query([q for (q, _) in sample], embeddings, return_size)\n",
    "    for (_, a), result_set in zip(sample, result_sets):\n",
    "        if a in result_set:\n",
    "            hits += 1\n",
    "    return hits / len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "00cdda06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return size: 005\tHit Rate: 0.10\tAvg Query Time: 0.37s\n",
      "Return size: 010\tHit Rate: 0.12\tAvg Query Time: 0.37s\n",
      "Return size: 020\tHit Rate: 0.14\tAvg Query Time: 0.37s\n",
      "Return size: 030\tHit Rate: 0.15\tAvg Query Time: 0.37s\n",
      "Return size: 050\tHit Rate: 0.17\tAvg Query Time: 0.37s\n",
      "Return size: 080\tHit Rate: 0.20\tAvg Query Time: 0.37s\n",
      "Return size: 100\tHit Rate: 0.20\tAvg Query Time: 0.37s\n",
      "Return size: 200\tHit Rate: 0.24\tAvg Query Time: 0.37s\n",
      "Return size: 500\tHit Rate: 0.29\tAvg Query Time: 0.37s\n"
     ]
    }
   ],
   "source": [
    "hit_rates = []\n",
    "times_elapsed = []\n",
    "return_sizes = [5, 10, 20, 30, 50, 80, 100, 200, 500]\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "for return_size in return_sizes:\n",
    "    hit_rate = get_hit_rate(short_q_links, all_embeddings, return_size)\n",
    "    hit_rates.append(hit_rate)\n",
    "    \n",
    "    end_time = time.perf_counter()\n",
    "    time_elapsed = (end_time - start_time) / len(short_q_links)\n",
    "    start_time = end_time\n",
    "    \n",
    "    times_elapsed.append(time_elapsed)\n",
    "    \n",
    "    print(\"Return size: {:03d}\\tHit Rate: {:.2f}\\tAvg Query Time: {:.2f}s\".format(return_size, hit_rate, time_elapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "40a725f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.plot(return_sizes, hit_rates)\n",
    "plt.title('Candidate Search Breadth vs. Retrieval Rate')\n",
    "plt.xlabel('Search Breadth')\n",
    "plt.ylabel('Retrieval Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d42d7c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Retrieval Rate</th>\n",
       "      <th>Random Baseline</th>\n",
       "      <th>Avg Query Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Search Breadth</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.098</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.371473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.115</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.372144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.136</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.370316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.151</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.369384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.175</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.369970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.197</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.369828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.204</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.366275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.236</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.367641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.286</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.365749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Retrieval Rate  Random Baseline  Avg Query Time\n",
       "Search Breadth                                                 \n",
       "5                        0.098         0.000017        0.371473\n",
       "10                       0.115         0.000034        0.372144\n",
       "20                       0.136         0.000068        0.370316\n",
       "30                       0.151         0.000102        0.369384\n",
       "50                       0.175         0.000170        0.369970\n",
       "80                       0.197         0.000272        0.369828\n",
       "100                      0.204         0.000340        0.366275\n",
       "200                      0.236         0.000679        0.367641\n",
       "500                      0.286         0.001698        0.365749"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df = pd.DataFrame({\n",
    "    \"Search Breadth\": return_sizes, \n",
    "    \"Retrieval Rate\": hit_rates,\n",
    "    \"Avg Query Time\": times_elapsed\n",
    "})\n",
    "metric_df[\"Random Baseline\"] = metric_df[\"Search Breadth\"] / len(all_embeddings)\n",
    "metric_df.index = metric_df[\"Search Breadth\"]\n",
    "metric_df[[\"Retrieval Rate\", \"Random Baseline\", \"Avg Query Time\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f3611a",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b8a70978",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs = pd.read_pickle('../formatted_data/stackoverflow/answer_title_body_lookup.pkl')\n",
    "qa_pairs_dict = dict(qa_pairs)\n",
    "\n",
    "def reranking(title_list, query, return_rate):\n",
    "    answers_list = []\n",
    "    query_embedding = get_sentence_embeddings(query)\n",
    "    \n",
    "    for idx in range(return_rate):\n",
    "        answers_list.append(qa_pairs_dict[title_list[idx]])\n",
    "        #print(idx+1,\":\",qa_pairs_dict[question_list[idx]])\n",
    "    answer_embeddings = get_sentence_embeddings(answers_list)\n",
    "    \n",
    "    return_answer_lookup = list(zip(title_list, answers_list))\n",
    "    \n",
    "    scored_answers = {}\n",
    "    for idx,answer_embedding in enumerate(answer_embeddings):\n",
    "        result = 1 - spatial.distance.cosine(query_embedding, answer_embedding)\n",
    "        scored_answers[result]=return_answer_lookup[idx]\n",
    "    ranked_answers = sorted(scored_answers.items(), key=lambda item: item[0], reverse = True)\n",
    "    \n",
    "    return ranked_answers\n",
    "\n",
    "def run_search_and_rank(query, pre_loaded_embeddings=None, return_rate=10):\n",
    "    \n",
    "    query = [query] # only one at a time\n",
    "    question_list = list(run_query(query, pre_loaded_embeddings, return_rate))[0]\n",
    "            \n",
    "    ranked_answers = reranking(question_list, query, return_rate)\n",
    "    \n",
    "    return [(s, t, b) for (s, (t, b)) in ranked_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "99861764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_rank(a_title, title_list):\n",
    "    if a_title not in title_list:\n",
    "        return None\n",
    "    return [i for (i, t) in enumerate(title_list) if t == a_title][0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e5d30c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to achieve const-correctness in C#? \"const correctness\" in C#\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "q, a = q_links[10]\n",
    "print(q, a)\n",
    "\n",
    "scores, titles, bodies = list(zip(*run_search_and_rank(q, all_embeddings, 5)))\n",
    "r = get_answer_rank(a, titles)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "797fbf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20)\n",
    "short_q_links = random.choices(q_links[:len(all_embeddings)], k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc471c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return size: 005\tAvg Rank: 2.40\tAvg Query Time: 2.56s\n",
      "Return size: 010\tAvg Rank: 4.20\tAvg Query Time: 2.97s\n",
      "Return size: 020\tAvg Rank: 8.20\tAvg Query Time: 3.94s\n",
      "Return size: 030\tAvg Rank: 12.20\tAvg Query Time: 4.89s\n",
      "Return size: 050\tAvg Rank: 19.10\tAvg Query Time: 6.78s\n",
      "Return size: 080\tAvg Rank: 29.00\tAvg Query Time: 9.82s\n"
     ]
    }
   ],
   "source": [
    "ranks = []\n",
    "rerank_times_elapsed = []\n",
    "\n",
    "for return_size in return_sizes:\n",
    "    \n",
    "    curr_ranks = []\n",
    "    curr_rerank_times_elapsed = []\n",
    "    \n",
    "    start_time = time.perf_counter()\n",
    "    for _, a in short_q_links:\n",
    "        _, titles, _ = list(zip(*run_search_and_rank(a, all_embeddings, return_size)))\n",
    "        end_time = time.perf_counter()\n",
    "        time_elapsed = end_time - start_time\n",
    "        \n",
    "        rank = get_answer_rank(a, titles)\n",
    "        curr_ranks.append(rank)\n",
    "        \n",
    "        start_time = end_time\n",
    "        curr_rerank_times_elapsed.append(time_elapsed)\n",
    "    \n",
    "    avg_rank = np.mean([rank for rank in curr_ranks if rank is not None])\n",
    "    avg_time = np.mean([time_elapsed for time_elapsed in curr_rerank_times_elapsed])\n",
    "    \n",
    "    ranks.append(avg_rank)\n",
    "    rerank_times_elapsed.append(avg_time)\n",
    "    \n",
    "    print(\"Return size: {:03d}\\tAvg Rank: {:.2f}\\tAvg Query Time: {:.2f}s\".format(return_size, avg_rank, avg_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae9e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.plot(return_sizes, ranks)\n",
    "plt.title('Candidate Search Breadth vs. Mean Rank')\n",
    "plt.xlabel('Search Breadth')\n",
    "plt.ylabel('Mean Rank')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae23502",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.plot(return_sizes, rerank_times_elapsed)\n",
    "plt.title('Candidate Search Breadth vs. Rank Runtime')\n",
    "plt.xlabel('Search Breadth')\n",
    "plt.ylabel('Avg Query Time (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20de0993",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_metric_df = pd.DataFrame({\n",
    "    \"Search Breadth\": return_sizes, \n",
    "    \"Mean Rank\": ranks,\n",
    "    \"Avg Rank Query Time\": rerank_times_elapsed\n",
    "})\n",
    "rank_metric_df.index = rank_metric_df[\"Search Breadth\"]\n",
    "rank_metric_df[[\"Mean Rank\", \"Avg Rank Query Time\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0731fd77",
   "metadata": {},
   "source": [
    "## VERIFY EMBEDDINGS AND STRINGS MATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b4fa7ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9999999403953552\n",
      "1 1.0\n",
      "2 1.0\n",
      "3 1.0\n",
      "4 0.9999998807907104\n",
      "5 0.9999998211860657\n",
      "6 1.0\n",
      "7 1.0\n",
      "8 0.9999998807907104\n",
      "9 1.0\n",
      "10 1.0\n",
      "11 0.9999998807907104\n",
      "12 0.9999999403953552\n",
      "13 1.0\n",
      "14 0.9999998807907104\n",
      "15 1.0\n",
      "16 1.0\n",
      "17 1.0\n",
      "18 1.0\n",
      "19 1.0\n",
      "20 1.0\n",
      "21 1.0\n",
      "22 1.0\n",
      "23 0.9999998807907104\n",
      "24 1.0\n",
      "25 0.9999999403953552\n",
      "26 0.9999998807907104\n",
      "27 0.9999998807907104\n",
      "28 0.9999998807907104\n",
      "29 0.9999998807907104\n",
      "30 1.0\n",
      "31 1.0\n",
      "32 1.0\n",
      "33 0.9999998807907104\n",
      "34 0.9999999403953552\n",
      "35 1.0\n",
      "36 1.0\n",
      "37 1.0\n",
      "38 1.0\n",
      "39 0.9999998807907104\n",
      "40 1.0\n",
      "41 1.0\n",
      "42 1.0\n",
      "43 0.9999998807907104\n",
      "44 1.0\n",
      "45 1.0\n",
      "46 0.9999998807907104\n",
      "47 1.0\n",
      "48 1.0\n",
      "49 0.9999998807907104\n",
      "50 1.0\n",
      "51 1.0\n",
      "52 1.0\n",
      "53 0.9999998807907104\n",
      "54 0.9999998807907104\n",
      "55 0.9999998807907104\n",
      "56 0.9999998807907104\n",
      "57 1.0\n",
      "58 1.0\n",
      "59 1.0\n",
      "60 1.0\n",
      "61 1.0\n",
      "62 1.0\n",
      "63 1.0\n",
      "64 1.0\n",
      "65 1.0\n",
      "66 0.9999998807907104\n",
      "67 1.0\n",
      "68 1.0\n",
      "69 0.9999998807907104\n",
      "70 0.9999998807907104\n",
      "71 0.9999998807907104\n",
      "72 1.0\n",
      "73 0.9999998807907104\n",
      "74 1.0\n",
      "75 0.9999998807907104\n",
      "76 1.0\n",
      "77 1.0\n",
      "78 1.0\n",
      "79 0.9999999403953552\n",
      "80 1.0\n",
      "81 1.0\n",
      "82 1.0\n",
      "83 1.0\n",
      "84 0.9999998807907104\n",
      "85 1.0\n",
      "86 1.0\n",
      "87 1.0\n",
      "88 0.9999998807907104\n",
      "89 1.0\n",
      "90 0.9999998807907104\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6d02a3a5ba38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'nan'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_sentence_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-88d185a945ea>\u001b[0m in \u001b[0;36mget_sentence_embeddings\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m#Pass tokens to model to obtain output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m#Obtain embeddings as last hidden state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         )\n\u001b[1;32m   1008\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m                 )\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         )\n\u001b[1;32m    479\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mmixed_query_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;31m# If this is instantiated as a cross-attention module, the keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Check cosine matches\n",
    "for i in range(0, 200):\n",
    "    print(i, 1 - spatial.distance.cosine(all_embeddings[i], get_sentence_embeddings([data[i]])[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
